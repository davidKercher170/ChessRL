# ChessRL
Chess model created using Deep Reinforcement Learning. Details the use of novel attention mechanisms and a new paradigm for transfer learning.

## Channel Attention
I use a variation of Efficient Channel Attention

@article{DBLP:journals/corr/abs-1910-03151,
  author       = {Qilong Wang and
                  Banggu Wu and
                  Pengfei Zhu and
                  Peihua Li and
                  Wangmeng Zuo and
                  Qinghua Hu},
  title        = {ECA-Net: Efficient Channel Attention for Deep Convolutional Neural
                  Networks},
  journal      = {CoRR},
  volume       = {abs/1910.03151},
  year         = {2019},
  url          = {http://arxiv.org/abs/1910.03151},
  eprinttype    = {arXiv},
  eprint       = {1910.03151},
  timestamp    = {Mon, 28 Oct 2024 15:53:08 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1910-03151.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
